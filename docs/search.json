[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BS3008: Computer Aided Drug Discovery",
    "section": "",
    "text": "This is a Quarto book website (authored in the form of a website) that I (i.e., Kevin) has authored for the SBS module BS3008: Computer Aided Drug Discovery (this module was formerly known as “Computational Biology”). As of the time of writing, BS3008 is a three academic unit (i.e., AU) module available to SBS students as a core module.\nBS3008 taught by professor Mu Yuguang."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Theoretical Foundations of BS3008",
    "section": "",
    "text": "This week’s (i.e., week 1) lecture aims to provide an introduction to BS3008’s course contents by explaining its various theoretical aspects."
  },
  {
    "objectID": "intro.html#discplines-in-bs3008",
    "href": "intro.html#discplines-in-bs3008",
    "title": "1  Theoretical Foundations of BS3008",
    "section": "1.1 Discplines in BS3008",
    "text": "1.1 Discplines in BS3008\nBS3008 covers numerous disciplines, including the following. A brief explanation on what each discipline is is also provided for each of the disciplines:\n\nChemoinformatics\nThis discipline deals with similarities and differences between chemical compounds.\nChemoinformatics deals with compounds from \\(10^{-60}\\) to \\(10^{-30}\\) in magnitudes. Individuals who work in this field try to find “an island in an ocean” - they try to find a molecule that can do some purpose.\nBioinformatics\nThis disciplines applies informatics tools (e.g., Python coding) to Biological molecules and data.\nBioinformatics mainly focuses on Biological modelling.\nTheoretical Chemistry (i.e., Quantum Chemistry)\nThis discipline provides the theoretical foundations needed to understand the course’s contents.\nComputational Chemistry and Biology\nThis discipline not only encompasses theoretical chemistry, but also molecular mechanics, minimization, simulations, and conformational analysis.\nMolecular Modelling\nThis discipline uses all of the above disciplines to represent and manipulate the structures of molecules.\nThis also means that this discipline uses physics to model a system - that way, a model can be compared against experimental results.\n\nHence, BS3008 primarily focuses on molecular modelling (with emphasis on theoretical chemistry for the theoretical component of the course).\n\n1.1.1 What is Molecular Modelling?\nAccording to Tamar Schlick, molecular modelling is:\n\n“…the science and art of studying molecular structure and function through model building and computation.”\n– Tamar Schlick\n\n“Computation” in this sense refer to practices such as:\n\nab initio and semi-empirical quantum mechanics\nMolecular mechanics\nMonte Carlo simulations\nMolecular dynamics\nFree energy and solvation methods\nStructure / activity relationships (i.e., SAR analyses)\nChemical / biochemical information and databases\n\nIt is important to understand that while “model building” can be as simple as using plastic or metal rods to depict molecules’ structures, it can also be as sophisticated as an interactive, animated color graphics and lasers.\nNonetheless, the computational tools used in molecular modelling is just as, if not more complex than Biological systems. However, the concepts in molecular modelling must be carefully applied and one must also be wary of molecular modeling’s strengths and weaknesses.\n\n\n1.1.2 Important Databases and Tools\nProfessor Mu lists some important molecular modelling tools in this chapter - click on their hyperlinks to access them:\n\nPDB\nThis is a database with numerous entries on proteins’ information.\nPDBBinding\nThis is another database that provides entries on the binding affinity for all biomolecular complexes.\nZINK DOCK\n\nAutodock Zina\nThis is an open-source program for performing molecular docking."
  },
  {
    "objectID": "wk2a.html",
    "href": "wk2a.html",
    "title": "2  Fundamental Quantum Chemistry",
    "section": "",
    "text": "Computational chemistry is a branch of chemistry that uses mathematical approximations and computer programs to obtain results (for chemical problems).\nComputational quantum chemistry focuses specifically on equations that have been derived from principles in quantum mechanics (i.e., solving Schrodinger’s equation for molecular systems).\nAb initio quantum chemistry uses methods that do not use any empirical data.\nComputational chemistry is a growing field: computers are getting faster and so are algorithms. This discipline can be used to calculate the following parameters:\nThe goal of this chapter is to provide a basic, high-level overview of quantum chemistry: necessary to use GaussianView and Gaussian 16."
  },
  {
    "objectID": "wk2a.html#born-oppenheimer-approximation",
    "href": "wk2a.html#born-oppenheimer-approximation",
    "title": "2  Fundamental Quantum Chemistry",
    "section": "2.1 Born-Oppenheimer Approximation",
    "text": "2.1 Born-Oppenheimer Approximation\nThis technique in computational chemistry leads to a later concept: potential energy surfaces (i.e., PES). A PES is a graph that describes the energy of a molecule (i.e., a system) in terms of certain parameters\nFor molecules that have many electrons, their wavefunction is a combination of electron and nuclear coordinates. Their wavefunctions can be represented as \\(\\psi(R, r)\\), where \\(R\\) are the nuclear coordinates and \\(r\\) the electron coordinates.\nHowever, nuclei are way heavier than electrons, nuclei also move much slower than electrons.\n\\[\\begin{equation}\n  \\psi(R, r) = \\psi_{et}(r; R)\\psi_N(R)\n\\end{equation}\\]\nThe Born-Oppenheimer approximation allows us to separate electrons and nuclear motion via the above wavefunction approximation.\n\n2.1.1 Schrodinger’s Equation\nThe time-independent Schrodinger equation is:\n\\[\\begin{align}\n  \\hat{H}\\psi &= E\\psi \\\\\n  \\hat{H} &= \\hat{T} + \\hat{V}\n\\end{align}\\]\nWhere \\(\\hat{H}\\) is the Hamiltonian, \\(\\psi\\) the wavefunction, and \\(E\\) the total amount of energy in the system.\n\\(T\\) represents kinetic energy and \\(V\\) the potential energy.\n\n\n2.1.2 Solutions of the Schrodinger Equation\nThe equation can only be solved for simple cases (e.g., particle in a box, hydrogen atoms, rigid rotors, etc). For more complex solutions, some assumptions will need to be made.\nSolving this equation also attempts to expand the wave function \\(\\psi\\) into one of many Slater determinants - these are represented by molecular orbitals: linear combinations of atomic-like-orbital functions.\nYet, it is still possible to get very accurate results. Generally speaking, the cost of calculation increases with the accuracy of the calculation (and the size of the system).\n\n\n2.1.3 Electronic Schrodinger Equation\nThis equation is as follows:\n\\[\\begin{align}\n  \\hat{H}_{el}\\psi_{el}(r; R) &=  E_{el}\\psi_{el}(r; R) \\\\\n  \\hat{H}_{el} &= -\\frac{\\hbar^2}{2m_e}\\sum_i\\nabla_i^2 - \\sum_\\alpha\\sum_i\\frac{Z_\\alpha e'^2}{r_{i\\alpha}} + \\sum_j\\sum_{i > j}\\frac{e'^2}{r_{ij}}\n\\end{align}\\]\nIn a typical potential energy graph, the potential energy takes a dip within a certain distance before it goes up:\n\n\n\n\n\nPotential Energy Graph for HgBr\n\n\n\n\nFrom the above graph, the following formulas can be derived:\n\\[\\begin{align}\n  U(R) &= E_{el} + V_{NN} \\\\\n  V_{NN} &= \\sum_\\alpha \\sum_{\\alpha > \\beta}\\frac{Z_\\alpha Z_\\beta e'^2}{r_{\\alpha\\beta}}\n\\end{align}\\]\n\n\n2.1.4 Nuclear Schrodinger Equation\nOnce a potential energy surface (i.e., PES) has been obtained for a molecule, one can solve the nuclear Schrodinger equation:\n\\[\\begin{align}\n  \\hat{H}_N\\psi_N(R) &= E_N\\psi_N(R) \\\\\n  \\hat{H}_N &= -\\frac{\\hbar^2}{2}\\sum_\\alpha\\frac{1}{m_\\alpha}\\nabla_\\alpha^2 + U(R)\n\\end{align}\\]\nThe solutions of this equation allow one to determine a large amount of molecular properties - for instance, vibrational energy levels.\n\n\n2.1.5 Polyatomic PESes\nWhere there are more than one parameters that are used to describe a molecule’s PES, the degrees of freedom is given by \\(3n - 6\\), where \\(N\\) is the number of atoms in the system."
  },
  {
    "objectID": "wk2a.html#basic-methods",
    "href": "wk2a.html#basic-methods",
    "title": "2  Fundamental Quantum Chemistry",
    "section": "2.2 Basic Methods",
    "text": "2.2 Basic Methods\n\n2.2.1 Solving the Electronic Schrodinger Equation\n\\[\\begin{equation}\n  \\hat{H}_{el} = -\\frac{\\hbar^2}{2m_e}\\sum_i\\nabla_i^2 - \\sum_\\alpha\\sum_i\\frac{Z_\\alpha e'^2}{r_{i\\alpha}} + \\sum_j\\sum_{i > j}\\frac{e'^2}{r_{ij}}\n\\end{equation}\\]\nThe final term \\(\\displaystyle \\sum_j\\sum_{i > j}\\frac{e'^2}{e_{ij}}\\) represents electron interactions. - this is the reason that it is impossible solve the electron schrodinger’s equation.\n\n2.2.1.1 Electron Spin and Antisymmetry\nAll electrons are described by a spin quantum number. The eigenfunctions describing these spins are denoted as \\(\\alpha\\) and \\(\\beta\\).\nElectron spin also obeys the following principles:\n\nIndisguinshability\nAll electrons that are spin-up are identical to one another.\nPauli’s Exclusion Principle\nNo two electrons can be described by the same set of quantum numbers.\n\nWhenever two electrons are interchanged, the signs of their wavefunctions are also changed - for instance:\nIf a wave function \\(\\psi = \\psi_a(1)\\alpha(1)\\psi_b(2)\\alpha(2)\\) is inverted, the result is \\(\\psi_a(2)\\alpha(2)\\psi_b(1)\\alpha(1) - \\psi_a(1)\\alpha(1)\\psi_b(2)\\alpha(2)\\).\n\n\n\n2.2.2 Slater Determinants\nAfter performing the Born-Oppenheimer approximation, one then determines the expansion of the electron wavefunction \\(\\psi_{el}\\) via Slater determinants:\n\\[\\begin{equation}\n  \\psi_{el} = \\sum_id_i\\phi_i = d_0\\phi_0 + d_1\\phi_1 + d_2\\phi_2 + ...\n\\end{equation}\\]\nThe Slater determinant \\(\\phi_0\\) is given via the below matrix. One can also choose to think about Slater determinants as a kind of “configuration” (i.e., ground-state neon might go something like \\(\\psi_0\\) = 1s22s22p6 and so on).\n\\[\\begin{equation}\n  \\phi_0 = \\frac{1}{\\sqrt{N!}}\\left[\n  \\begin{matrix}\n    \\phi_1\\alpha(1) & \\phi_1\\beta(1) & \\phi_2\\alpha(1) & ... & \\phi_M\\beta(1) \\\\\n    \\phi_1\\alpha(2) & \\phi_1\\beta(2) & \\phi_2\\alpha(2) & ... & \\phi_M\\beta(1) \\\\\n    ... & .... & ... & ... & ... \\\\\n    \\phi_1\\alpha(N) & \\phi_1\\beta(N) & \\phi_2\\alpha(N) & ... & \\phi_M\\beta(N)    \n  \\end{matrix}\n  \\right]\n\\end{equation}\\]\nWhere:\n\n\\(\\alpha\\) and \\(\\beta\\) are the spin-up and spin-down functions respectively.\n\\(\\psi_i\\) the spatial functions\n\\(\\psi_i\\alpha\\) and \\(\\psi_i\\beta\\) the spin-orbitals\n\nSlater determinants give proper anti-symmetry (i.e., the Pauli Exclusion Principle).\n\n\n2.2.3 Hartree-Fock Approximations\nIt is impractical (and impossible) to consider all configurations of a system \\(\\phi_i\\). Hence, the Hartree-Fock approximation is often used to approximate the wavefunction for the complete set of \\(\\phi_i\\)s using a single determinant \\(\\psi_0\\).\nIn this method, Self-consistent field energies (i.e., SCF energies) are used instead to find an optimal set of molecular orbitals for \\(\\psi_0\\).\nEach electron in this approximation only sees an average repulsion of the remaining electrons.\n\n2.2.3.1 How Accurate is the Approximation?\n\n\n\n\n\nTotal Accuracy of a Hartree-Fock Approximation on a CO Molecule\n\n\n\n\nHartree-Fock wavefunctions usually approximate about 99% of the total energy. Hartree-Fock approximations can also be used to predict bond angles, thermochemistry measurements (e.g., enthalpy), and even vibrational force constants.\nQuantum chemists are typically interested in energy differences and not total energies.\n\n\n2.2.3.2 Electron Correlations\nThe electron correlation is the energy difference between an experimentally measured value (i.e., the “exact” value) and value obtained from a Hartree-Fock approximation. In more empirical terms:\n\\[\\begin{equation}\n  E_{corr} = E_{exact} - E_{HF}\n\\end{equation}\\]\nThe \\(E_{corr}\\) accounts for missing electron-electron interactions in the Hartree-Fock method.\nBecause of this, the Hartree-Fock approximation is often used as a “starting point” for finding the wavefunction.\nDo also note that different correlation methods also exist - depending on which values of \\(\\phi_i\\) and \\(d_i\\) to use, the value of \\(E_{corr}\\) might change.\n\n\n2.2.3.3 Configuration Interactions\nFirst suppose the following about electron wavefunction:\n\\[\\begin{equation}\n  \\psi_{el} = d_0\\phi_{HF} + \\sum_{i = 1}d_i\\phi_i\n\\end{equation}\\]\nThe above assumption uses the linear variation principle: the amount energy in a wavefunction is always equal to or great than the true energy.\nSome other possible configurations (i.e., methods) include:\n\nCISD\nThis is short for Configuration Interaction with Single and Double excitations. All determinants of “s” and “d” type orbitals are used.\nMRCI\nThis is short for Multireference Configuration Interaction.\n\nBoth CISD and MRCI can be very accurate, but they also take a long time to process.\n\n\n\n2.2.4 Mollet-Plesset (i.e., MP) Perturbation Theory\nPerturbation methods such as these assume that the problem at hand (i.e., \\(\\psi\\) and \\(E\\)) only differ slightly from a solved problem (i.e., \\(HF_{\\psi}\\) and \\(E\\)).\nThe energy is calculated via various orders of approximations. At MP2, the calculation involves single and double excitations; higher MPs result in costlier calculations.\n\n\n2.2.5 Coupled Cluster (i.e., CC) Theory\nThis theory leads to accurate wavefunction expansions (and yields accurate electronic charges).\nSome common variants of this include:\n\nCCSD\nWhich includes single and double CCs, hence its name.\nCCSD(T)\nThis is the same as CCSD, albeit with treatments of triple excitations. This method uses accurate results when used on large basis sets.\nIt’s possible to get thermochemical results (i.e., enthalpy) with good accuracy.\n\n\n\n2.2.6 Frozen Core Approximations\nHere, only valence orbitals are involved in chemical bonding processes. Core orbitals don’t change much when atoms are involved in molecules (as opposed to when atoms are free).\nBecause of this, most electronic structure calculations only correlate with the frozen electrons (i.e., the core orbitals are kept frozen).\n\n\n2.2.7 Density Frozen Theory\nThe wavefunction is generally uninterpretable1.\nNonetheless, a useful physical observation would be an atom’s electron density \\(\\rho\\) as it gives the total number of electrons over space.\nDensity Functional Theory solves for electron density. The cost of such method is similar to Hartree-Fock approximations (and usually involve some of empirical parameterization).\nThis approach is often the best choice when dealing with large molecules."
  },
  {
    "objectID": "wk2a.html#basis-sets",
    "href": "wk2a.html#basis-sets",
    "title": "2  Fundamental Quantum Chemistry",
    "section": "2.3 Basis sets",
    "text": "2.3 Basis sets\n\n2.3.1 Linear Combination of Atomic Orbitals-Molecular Orbitals\nGiven the Slater determinant \\(\\phi_0\\):\n\\[\\begin{equation}\n    \\phi_0 = \\frac{1}{\\sqrt{N!}}\\left[\n  \\begin{matrix}\n    \\phi_1\\alpha(1) & \\phi_1\\beta(1) & \\phi_2\\alpha(1) & ... & \\phi_M\\beta(1) \\\\\n    \\phi_1\\alpha(2) & \\phi_1\\beta(2) & \\phi_2\\alpha(2) & ... & \\phi_M\\beta(1) \\\\\n    ... & .... & ... & ... & ... \\\\\n    \\phi_1\\alpha(N) & \\phi_1\\beta(N) & \\phi_2\\alpha(N) & ... & \\phi_M\\beta(N)    \n  \\end{matrix}\n  \\right]\n\\end{equation}\\]\nThe spatial functions \\(\\phi_i\\) can be calculated via the following equation:\n\\[\\begin{equation}\n  \\phi_i = \\sum_k^Mc_{ki}\\chi_k\n\\end{equation}\\]\nWhere \\(c_{ki}\\) molecular orbital coefficients that are calculated in the SCF procedure previous outlined and \\(\\chi_k\\) atom-centric functions that mimic solutions of hydrogen atoms (i.e., s and p orbitals).\nJust like other calculations, the more accurate a calculation is, the more expensive it becomes.\n\n\n2.3.2 Gaussian Type Orbitals\n\n\n\n\n\nGraph of a Slater-Type Function Against a Gaussian-Type Function\n\n\n\n\n\\(l_x\\), \\(l_y\\), and \\(l_z\\) in the above graphic determines the kinds of orbitals in question (e.g., \\(l = 1\\) represents a “p” orbital).\nThe solutions of a hydrogen atom come in the form of a Slater-type function (most of which are electronic structure theory calculations):\n\\[\\begin{equation}\n  \\chi_{\\alpha, n, l, m}(r, \\theta, \\phi) = NY_{l, m}(\\theta, \\phi)r^{n - 1}e^{-\\alpha r}\n\\end{equation}\\]\nWhere \\(\\chi\\) can be a single Gaussian function (i.e., primitives) or a linear combination of Gaussian functions (i.e., contractives).\n\n\n2.3.3 Single \\(\\zeta\\), Mutliple-\\(\\zeta\\), and Split-Valences\n\\[\\begin{equation}\n  \\psi(x, y, z; \\{\\alpha\\}, i, j, k) = \\sum_{a = 1}^Mc_a\\phi(x, y, z; \\alpha_a, i, j, k)\n\\end{equation}\\]\nSTO-MG (where \\(M\\) is between two and six) is short for Slater Type Orbital approximated by M Gaussians. Quantum chemists found via experimentation that \\(M = 3\\) gave the best combination of speed and accuracy.\nTo increase the flexibility of a basis set, one might choose to take a STO-3G basis set and construct two basis functions for each atomic orbital. The first atomic orbital could be a contraction of the first two primitive Gaussians while the second could be a normalized third primitive. A basis with two functions for each atomic orbital is called a double-\\(\\zeta\\) basis.\nMore decontractions are possible - this would give rise to higher, multiple-\\(\\xeta\\) basis sets. More examples of such sets include cc-pCVDZ and cc-pCVTZ.\n\n\n2.3.4 Polarization Functions\nDue to the utility of atomic-orbital-like gaussian type orbitals, this amount of flexibility is often provided in the form of one quantum number higher of higher angular momentum than the valence orbitals. Thus, for a first-row atom, the most useful polarization function are d-GTOs2, and for hydrogens, p-GTOs.\nAdding a d-function to nitrogen’s basis set causes Hartree-Fock approximations to correctly predict a trigonal pyrimidal shape for ammonica.\n\n\n2.3.5 Diffuse Functions\nThe highest-energy molecular orbitals of anions, highly-excited electron states, and loose supermolecular complexes are more spatially diffuse than garden-variety molecular orbitals.\nWhen a basis set doesn’t have enough flexibility to allow a weakly-bonded electron to localize far from the remaining density, significant errors in energies and other molecular properties can occur.\nTo address the aforementioned, standard basis sets often augmented with diffuse basis functions when their use is warranted.\n\n2.3.5.1 Pople and Dunning-Style Basis Sets\n\n2.3.5.1.1 Pople-Style Basis Sets\nThis was named after professor John Pople who won the Nobel Prize in Chemistry in 1998 for his work in quantum chemistry.\n\n\n\n\n\nNotation for a Pople-Style Basis Set\n\n\n\n\nIn this family, diffuse functions are denoted by having a “+” in their basis sets’ names. Hence, “6-31 + G(d)” means that heavy atoms have been augmented with one additional “one s” and one set of “p” functions that have small exponents.\nA second plus indicates diffuse “s” functions on a hydrogen atom (e.g., “6-3H++G(3d,f 2pd)”).\n\n\n2.3.5.1.2 Dunning-Style Basis Sets\nHere, diffuse functions are indicated by an “aug”; one set of diffuse functions will be added for each angular momentum already present. Hence “aug-cc-pVTZ” has diffuse “s”, “p”, “d”, and “f” functions on heavy atoms and diffuse “s”, “p”, and “d” functions on hydrogen and helium atoms.\n\n\n\n\n2.3.6 Correlation-Consistent Basis Sets\nThese are designed so that have the unique property of forming a systematically-converging set.\nCorrelations with correlation consistent (i.e., cc) basis sets lead to accurate estimates of the complete basis set limit (i.e., CBS) limit.\n\n\n\n\n\nCorrelation-Consistent Basis Sets\n\n\n\n\nProfessor Mu’s slides lists the notation of cc sets and some examples."
  },
  {
    "objectID": "wk3.html",
    "href": "wk3.html",
    "title": "3  Molecular Mechanics in Molecular Modelling",
    "section": "",
    "text": "Molecular modelling started with the idea that molecular geometry, energy, and other molecular properties could be calculated from models (that are influenced by basic forces).\nA molecule - hence - is a system of particles (i.e., atoms) connected by springs (i.e., bonds). This molecule is free to rotate, vibrate, and adopt a favorable conformation in space as a result of the inter- and intramolecular forces acting upon it."
  },
  {
    "objectID": "wk3.html#structure-topology-motion-functions-and-potential-energy",
    "href": "wk3.html#structure-topology-motion-functions-and-potential-energy",
    "title": "3  Molecular Mechanics in Molecular Modelling",
    "section": "3.1 Structure, Topology, Motion, Functions, and Potential Energy",
    "text": "3.1 Structure, Topology, Motion, Functions, and Potential Energy\nThis section aims to illustrate how different energy functions can influence the behavior of particles in a system.\n\n3.1.1 Case #1\n\n\n\n\n\nA Simple System to Consider\n\n\n\n\nThe potential and kinetic energy \\(E_p\\) and \\(E_k\\) respectively in this system is given by:\n\\[\\begin{align}\n  E_p &= E_p(\\vec{x}) = \\sum_{i}f_i(x, y, z) \\\\\n  E_k &= \\frac{1}{2} \\cdot (m_1v_1^2 + m_2v_2^2)\n\\end{align}\\]\nWhere \\(\\vec{x}\\) is the system and \\(f_i(x, y, z)\\) a function that calculates the potential energy for each particle in the system (i.e., each atom). Hence, we can say that:\n\\[\\begin{equation}\n  E_{tot} = E_p + E_k\n\\end{equation}\\]\nWhere \\(E_{tot}\\) is the total energy of the system.\nSince \\(r\\) represents the distance between both molecules, therefore \\(E_p(r) = 0\\).\n\\[\\begin{equation}\n  \\vec{F} = \\frac{\\partial E_p(\\vec{x})}{\\partial \\vec{x}}\n\\end{equation}\\]\nThe force1 \\(\\vec{F}\\) on the system is denoted via the above equation.\nSince \\(E_p(r) = 0\\) in the first figure, it follows that \\(F(r) = 0\\).\n\n\n3.1.2 Case #2\n\n\n\n\n\nA System with Two Charged Molecules\n\n\n\n\nHere, the charge \\(V_{ele}\\) and the potential energy \\(E_p(r)\\) is given via the following equations:\n\\[\\begin{align}\n  V_{ele}(r) &= \\frac{1}{4\\pi \\epsilon_0} \\cdot \\frac{q_1}{r} \\\\\n  E_p(r) &= \\frac{1}{4\\pi \\epsilon_0} \\cdot \\frac{q_1q_2}{r}\n\\end{align}\\]\nSome important considerations to think about include the variables and the parameters of the system.\n\n\n3.1.3 Case #3\n\n\n\n\n\nA System with Two Molecules and their Energy Graph\n\n\n\n\nIn this system, we let:\n\\[\\begin{equation}\n  E_p(r) = 4\\epsilon\\left[\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]\n\\end{equation}\\]\nIn this system, we also note that \\(E_p(r) = 0\\) when \\(r = \\sigma\\) and that \\(\\displaystyle E_p(\\sqrt[6]{2}\\sigma) = -\\epsilon\\).\nDo also consider the variables and parameters in this system (and whether or not both particles in this system can move freely).\n\n\n3.1.4 Case #4\n\n\n\n\n\nA System with Two Molecules and their Energy Graph\n\n\n\n\nHere, we define the system’s potential energy \\(E_p\\) as:\n\\[\\begin{equation}\n  E_p(r) = \\frac{1}{2}k(r - r_0)^2\n\\end{equation}\\]\nWhile the energy graph for this system appears to be that of bonding, it is still important to consider the variables and the parameters of the system.\nWe can also further decompose the above equation to its spatial components \\(x\\), \\(y\\), and \\(z\\) and say that:\n\\[\\begin{equation}\nE_p(r) = \\frac{1}{2}k(x - x_0)^2 + \\frac{1}{2}k(y - y_0)^2 + \\frac{1}{2}k(z - z_0)^2\n\\end{equation}\\]\nIn this sub-case, the system appears to be a lattice. However, are the particles still movable?"
  },
  {
    "objectID": "wk3.html#professor-mus-current-works",
    "href": "wk3.html#professor-mus-current-works",
    "title": "3  Molecular Mechanics in Molecular Modelling",
    "section": "3.2 Professor Mu’s Current Works",
    "text": "3.2 Professor Mu’s Current Works\nAs of the time of writing, professor Mu’s lab is currently focused on the following topics:\n\nAmyloidogenic protein / peptide aggregation and misfolding\nDNA-DNA, DNA-ions, and DNA-protein interactions\nDrug-protein interaction and drug candidate screening\nPeptide-membrane interactions.\n\nFor more information on professor Mu’s current research topics, do visit his lab’s homepage."
  },
  {
    "objectID": "wk2.html",
    "href": "wk2.html",
    "title": "4  Force Fields",
    "section": "",
    "text": "A force field implies that a molecule’s atoms are a collection of different matter interacting with one another via forces described by empirical energy functions. This is unlike quantum mechanical calculations: the electrons and atoms’ nuclei are not explicitly included in such calculations.\nForce fields provide a fast computational method that works for small and big molecules alike (and even complex molecular systems)."
  },
  {
    "objectID": "wk2.html#typical-force-fields",
    "href": "wk2.html#typical-force-fields",
    "title": "4  Force Fields",
    "section": "4.1 Typical Force Fields",
    "text": "4.1 Typical Force Fields\nA typical force field \\(U(\\{r_{ij}\\})\\) has the following formula:\n\\[\\begin{align}\n  U(\\{r_{ij}\\}) = &\\sum_j\\frac{k^l_j}{2}(l_j - l^0_j)^2 + \\sum_j\\frac{k^\\delta_j}{2}(\\delta_j - \\delta_j^0)^2 + \\sum_{torsions}\\frac{V_n}{2}(1 + \\cos(n\\phi - \\gamma)) \\\\ &+   \n  \\sum_{i, j = 1}^N\\frac{q_iq_j}{r_{ij}} + \\sum_{i, j = 1}^N4\\epsilon_{ij}\\left[\\left(\\frac{\\sigma_{ij}}{r_{ij}}\\right)^{12} - \\left(\\frac{\\sigma_{ij}}{r_{ij}}\\right)^6\\right]\n\\end{align}\\]\nOr in more layman terms:\n\\[\\begin{align}\n  \\text{Force field} = &\\text{ bond stretching} + \\text{valence angle bending} \\\\\n  &+ \\text{torsions} + \\text{Electrostatic charges} \\\\\n  &+ \\text{van der Waals forces}\n\\end{align}\\]\nBoth bond stretching and valence angle bending refer to intramolecular forces. This is in contrast to electrostatic charges and van der Waals forces: intra- and intermolecular bonding.\n\n4.1.1 Bond Stretching\nThe Morse potential \\(E(l)\\) and the Harmonic potential \\(a\\) are:\n\\[\\begin{align}\n  E(l) &= D_e\\{1 - \\exp[-a(l - l_0)]\\}^2 \\\\\n  a &= \\omega \\sqrt{\\frac{\\mu}{2D_e}}\n\\end{align}\\]\n\\(D_e\\) in the above equations represent the depth of the potential energy minimum:\n\n\n\n\n\nA Potential Energy Graph Between an Oxygen Atom and a Hydrogen Atom\n\n\n\n\n\\(\\omega\\) represents the bond vibration frequency, \\(\\mu\\) the reduced mass, and \\(l_0\\) the reference bond length1\n\n4.1.1.1 At Room Temperature (i.e., 298 K)\nIn such a case, the thermal kinetic energy of the system (i.e., molecule) falls within \\(\\displaystyle \\frac{1}{2}k_BT\\) and \\(300 K\\). An approximation for the thermal kinetic energy \\(E_{thermal}\\) is about 0.3 kcal / mol. We can also say that:\n\\[\\begin{align}\n  E(l) &= \\frac{1}{2}k(l - l_0)^2 \\\\\n  k &= 2D_ea^2 = \\mu\\omega^2\n\\end{align}\\]\nAt room temperature, the energy potential of a molecule can be described via the following graph:\n\n\n\n\n\nA Potential Energy Well at Room Temperature\n\n\n\n\nThis graph is also called a Hooke’s spring.\n\n\n\n4.1.2 Angle Bending\n\n\n\n\n\nInformation on Several Bond Angles\n\n\n\n\nBecause of a covalent bond’s directionality, its bond angles do not change that much.\n\\[\\begin{equation}\n  E(\\theta) = \\frac{k}{2}(\\theta - \\theta_0)^2\n\\end{equation}\\]\nTherefore, Hooke’s law is often used to calculate the harmonic potential energy of a certain type of bond angle.\n\n\n4.1.3 Torison Terms\n\n\n\n\n\nProfessor Mu’s Slides on Torsion Terms and Dihedral Angles\n\n\n\n\nThe torsional energy is defined between every quartet of atoms - it depends on the dihedral angle \\(\\phi\\) made by two planes (and also incorporating the first and last three terms in the torsion).\n\\[\\begin{equation}\n  E(\\psi) = \\sum_{n = 0}^N\\frac{V_n}{2}[1 + \\cos(n\\psi - \\psi_0)]\n\\end{equation}\\]\nTorsional motions are typically hundreds of times less stiff than bond stretching motions.\nTorsion terms also mimic bonding characteristics and neighboring atoms’ and their side groups’ steric hindrances about the chain axis.\n\n4.1.3.1 Exammple Torsional Terms for Ethane\n\n\n\n\n\nExample Torsional Term for an Ethane Molecule\n\n\n\n\nNote that the y-axis of the above graphic is in kcal / mol.\n\n\n\n4.1.4 Non-Bonded Interactions\n\n\n\n\n\nNomenclature for Non-Bonded Interactions\n\n\n\n\nThe kind of bonded interactions depend on the bonding relationship between atoms. Such energy functions in this scenario describe the total interactions between atoms and cannot be further decomposed.\n\n\n4.1.5 Electrostatic Interactions\nThis is a group in its own right - the other group of non-bonded terms is van der Waals interactions.\n\\[\\begin{equation}\n  E_{ele} = \\sum_{i > j}\\frac{1}{4\\pi\\epsilon_0}\\frac{q_iq_j}{r_{ij}}\n\\end{equation}\\]\nIn a simple model consisting of two water molecules, their partial charges are \\(q_O = -0.834\\) and \\(q_H = 0.417\\).\n\n4.1.5.1 Calculating Partial Charges\nA molecule’s electrostatic potential can be measured - it can also be determined from molecular wavefunctions (from quantum mechanics):\n\\[\\begin{equation}\n  R = \\sum_{i = 1}^{N_{points}}(\\phi_i^{calc} - \\phi_i^0)^2\n\\end{equation}\\]\nThe goal is to find a set partial charge from which the calculated potentials are closest to the reference ones.\n\n\n\n4.1.6 van der Waals Interactions\nThey arise from a balance between attractive and repulsive forces.\nThe attractive force is due to dispersion forces and is equivalent to \\(\\displaystyle \\frac{1}{r^6}\\). The repulsive force originates from quantum mechanics and can be understood using Pauli’s exclusion principle.\n\n4.1.6.1 Lennard-Jones Potential\nThe Lennard-Jones 12-6 function \\(\\displaystyle 4\\epsilon\\left[\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^6\\right]\\) has two adjustable parameters:\n\nCollision diameter \\(\\sigma\\)\nWell depth \\(\\sigma\\)\n\nThe \\(\\displaystyle \\frac{1}{r^{12}}\\) is questionable at times, but also allows for rapid computations.\n\n\n4.1.6.2 Combination Rules\nA way to approximate parameters is needed to calculate the van der Waals interactions between different kinds of atoms.\nThere are two methods covered in BS3008:\n\nAmber and Charmm\n\\[\\begin{align}\n  \\epsilon_{ij} &= \\sqrt{\\epsilon_i\\epsilon_j} \\\\\n  \\sigma_{ij} &= \\frac{\\sigma_i + \\sigma_j}{2}\n\\end{align}\\]\nThe Lorentz-Berthelodt rules are used.\nOPLS2 Force Fields\n\\[\\begin{align}\n  \\epsilon_{ij} &= \\sqrt{\\epsilon_i\\epsilon_j} \\\\\n  \\sigma_{ij} &= \\sqrt{\\sigma_i\\sigma_j}\n\\end{align}\\]\n\n\n\n4.1.6.3 Parameters of van der Waals Forces\nThe Lennard Johnson (i.e., LJ) parameters state the following:\n\nHeat of vaporization\nDensity (i.e., molecular volume)\nPartial Molar Volume\nCrystal simulations"
  },
  {
    "objectID": "wk2.html#common-empirical-force-fields",
    "href": "wk2.html#common-empirical-force-fields",
    "title": "4  Force Fields",
    "section": "4.2 Common Empirical Force Fields",
    "text": "4.2 Common Empirical Force Fields\nBS3008 lists several different force fields for one’s own reference:\n\nClass I Force Fields\n\nCHARMM\nCHARMm\nAMBER\nOPLS / Schrodinger\nECEPP (i.e., free energy force field)\nGROMOS\n\nClass II Force Field\n\nCFF95\nMM3\nMMFF94\nUFF, DREIDING\n\n\n\n4.2.1 On Class II Force Fields\n\n\n\n\n\nEquation and Summary of Class II Force Fields\n\n\n\n\nThe above image was taken off professor Mu’s teaching slides."
  },
  {
    "objectID": "wk5.html",
    "href": "wk5.html",
    "title": "5  Realization of Force Field and Energy Minimalization",
    "section": "",
    "text": "Illustrations of Different Parameters in a Sample System\nThe potential energy \\(V(r)\\) for any force field is:\n\\[\\begin{align}\n  V(r) &= \\sum_{\\text{bonds}}k_b(b - b_0)^2 + \\sum_{\\text{angles}}k_\\theta(\\theta-\\theta_0)^2 + \\sum_{\\text{torsions}}k_\\phi[\\cos(n\\phi + \\delta) + 1] \\\\\n  &+ \\sum_{\\text{nonbonded pairs}}\\left[\\frac{q_iq_j}{r_{ij}} + \\frac{A_{ij}}{r_{ij}^{12}} - \\frac{C_{ij}}{r_{ij}^6}\\right]\n\\end{align}\\]\nThis lecture covers different kinds of force fields."
  },
  {
    "objectID": "wk5.html#types-of-force-fields",
    "href": "wk5.html#types-of-force-fields",
    "title": "5  Realization of Force Field and Energy Minimalization",
    "section": "5.1 Types of Force Fields",
    "text": "5.1 Types of Force Fields\nBS3008 covers three kinds:\n\n5.1.1 AMBER Force Fields\nThese were developed by the Kollman Group at the University of California, San Francisco from the early 1980s until now.\nThe charges in this force field were derived from quantum chemistry calculations at the Hartree-Fock STO-3G level via fitting of partial atomic charges to the quantum electrostatic potential. These forces are called ESP (i.e., Electrostatic potential) charges.\nThe van der Waals terms were adopted from amide crystal data from a research group (i.e., Lifson) and from liquid-state simulations by another research group (i.e., Jorgensen).\nForce constants and idealized bond lengths and angles were taken from crystal structures and adapted to match normal frequencies for a number of peptide fragments.\nTorsion force constants were adjusted to match torsional barriers from experiment or from quantum chemistry calculations.\nThe values in an AMBER force field are closely coupled to non-bonded potentials and are hardly transferrable from one force field to another.\n\n\n5.1.2 OPLS Force Fields\nOPLS is short for Optimized Potential for Liquid Simulation. OPLS force fields were developed by Jorgensen and co-workers at Yale university to simulate liquid-state properties for water and more than 40 organic liquids.\nOPLS force fields placed a strong emphasis on deriving non-bonded interactions in comparison to liquid-state thermodynamics. The earliest application of an OPLS force field was to that of rigid-molecule Monte Carlo simulations of the structure and thermodynamics of hydrofluoric acid (i.e., liquid HF).\n\n5.1.2.1 Change in OPLS Performance\n\n\n\n\n\nRamachandran Plots of an OPLS Force Field\n\n\n\n\nIn 2001, the OPLS-AA performance for peptides was refitted by key Fourier torsional coefficients.\nThis technique uses experimental data as its target to choose a suitable subspace of the whole potential energy surface and to determine weights for each of the fitting points based on gradients.\n\n\n\n\n\nExperimental Results for Liquid Densities, Heats of Vaporization, and Free Energies of Hydration (from left to right)\n\n\n\n\nThe average energy deviation (in root mean squared) from the LMP2/cc- pVTZ(-f)//HF/6-31G** data has been reduced by 40% from 0.81 to 0.47 kcal / mol due to fitting for electrostatically uncharged dipeptides.\n\n\n\n5.1.3 CHARMM Force Fields\nCHARMM is short for Chemistry at Harvard using Molecular Mechanics; this force field was developed in the early 1980s by the Karplus group. The goal of CHARMM was to obtain a balanced interaction between solute-water and water-water energies when the latter are represented by TIP3P.\nFor peptides, it was found that peptide-water interactions led to peptide-peptide hydrogen bonds that were larger than HF/6-31G values by a factor of close to 1.6.\nLennard-Jones parameters were then refined to reproduce densities and heats of vaporization of liquids (along with unit cell parameters and sublimation heat for crystals).\nQuantum calculations at the HF/6-13G level of hydrogen bond complexes between water and hydrogen bond donors or acceptors of amino acids or fragments.\nThe above set of calculations involves a series of supermolecular calculations of the model compound (e.g., formamide or a single water molecule).\n\n5.1.3.1 Change in CHARMM Force Fields\nIn 2004, a new parameter was introduced such that:\n\\[\\begin{equation}\n  V_{\\text{cross}} = K_{n, m}(1 + \\cos(n\\phi + m\\psi - \\delta_{n, m}))\n\\end{equation}\\]\nMolecular dynamics simulations of up to seven proteins in their crystalline environments were used to validate force field enhancements.\n\n\n\n5.1.4 Applications of Force Fields in Practice\nIn a non-bonded kind of interaction, the van der Waals parameters are; \\(\\epsilon\\) and \\(\\sigma\\). In a bonded interaction, the van der Waals parameters are:\n\nAn equilibrium bond length \\(l_0\\) with a force constraint \\(k\\).\nAn equilibrium angle \\(\\alpha_0\\) with a force constraint \\(k\\)\nTorsional angle terms \\(V_i\\), \\(n_i\\), and \\(\\theta_i\\).\n\nIn a database (i.e., topological library), atom types, partial charges, and chemical bonding information are included."
  },
  {
    "objectID": "wk5.html#gromacs-software",
    "href": "wk5.html#gromacs-software",
    "title": "5  Realization of Force Field and Energy Minimalization",
    "section": "5.2 GROMACS Software",
    "text": "5.2 GROMACS Software\n\n\n\n\n\nExample of GROMACS Input\n\n\n\n\nGROMACS is short for GROningen MAchine for Chemical Simulation. GROMACS is an inter-group effort between different project groups in the University of Groningen’s chemistry department (located in the Netherlands).\n\n\n\n\n\nA GROMACS Simulation with a Four-Point Water Molecule\n\n\n\n\nThe [settle] section defines the first atom of a water molecule in a water molecule. The H-H and the O-H distances must always be given - this algorithm can also be used for TIP3P and TIP4P.\n\n\n\n\n\nEnergy of a Water Molecule in Different Systems\n\n\n\n\nThe above graphs shows computed and experimental results for the density of liquid water versus the temperature at 1 atm."
  },
  {
    "objectID": "wk5.html#minimization",
    "href": "wk5.html#minimization",
    "title": "5  Realization of Force Field and Energy Minimalization",
    "section": "5.3 Minimization",
    "text": "5.3 Minimization\nAs the initial structure of an atom is usually taken from a guess (e.g., particle in a box model), there could be unexpected, “bad” contacts between atoms.\nIf a system has \\(N\\) atoms, then there are \\(3N\\) coordinates or \\(3N - 6\\) internal coordinates - these coordinates all define multi-dimensional PES (i.e., potential energy surface).\nA process is needed to find the local minimum of a PES. Minimization is typically performed after model building\n\n\n\n\n\nMeanings of Derivatives in Multivariable Calculus\n\n\n\n\nGiven a function \\(\\displaystyle f = f(x_1, x_2, x_3, ...)\\), we need to find the values of \\(x\\) such that \\(f\\) will be a minimum - in other terms:\n\\[\\begin{align}\n  \\frac{\\partial f}{\\partial x_i} &= 0 & \\frac{\\partial^2 f}{\\partial x_i^2} &> 0\n\\end{align}\\]\n\\(f\\) can usually be a function dealing with quantum mechanics energy or molecular mechanics energy, while \\(x\\) can deal with Cartesian coordinates (in molecular mechanics) or internal coordinates (as is the case with quantum mechanics).\n\n5.3.1 Minimization Methods\n\n5.3.1.1 Simplex Method\nA simplex is a geometric figure with \\(M + 1\\) connected vertices, where \\(M\\) is the dimensionality of the energy function.\n\n\n\n\n\nMinimum Point on a Simplex Function\n\n\n\n\nThe minima is / are usually found via reflection, reflection-and-expansion, and contraction.\n\n\n5.3.1.2 Derivative Minimization Methods\nA Taylor series can be used to expand a function at a point \\(x_0\\):\n\\[\\begin{equation}\n  V(x) = v(x_0) + \\frac{dV(x)}{dx}(x - x_0) + \\frac{d^2V(x)}{dx^2} \\cdot \\frac{(x - x_0)^2}{2}\n\\end{equation}\\]\nIf \\(V(x)\\) is a function of \\(N\\) variables, then \\(V'(x_k)\\) is the \\(N*1\\) matrix - hence, \\(V''\\) should be re-written as \\(\\displaystyle \\frac{\\partial^2V}{\\partial x_{k1}\\partial x_{k2}}\\). This matrix is then known as the Hessian matrix or the force constant matrix.\n\n\n5.3.1.3 First Order Minimization Methods\n\n\n\n\n\nIllustration of a Steepest Descent Method\n\n\n\n\nThe steepest descent method moves in the direction parallel to the net force - this is like walking downhill.\n\\[\\begin{align}\n  s_k &= \\frac{-g_k}{|g_k|} & g_k &= \\frac{\\partial V}{\\partial x_k}\n\\end{align}\\]\n\n\n\n\n\nConjugate Gradients Method\n\n\n\n\nThe conjugate graidents methods not only considers net force, but also takes the previous move step into consideration.\n\\[\\begin{align}\n  s_k &= -g_{k - 1} + \\gamma_ks_{k - 1} & \\gamma_k &= \\frac{s_{k - 1} \\cdot g_{k - 1}}{s^2_{k - 1}}\n\\end{align}\\]"
  },
  {
    "objectID": "wk6.html",
    "href": "wk6.html",
    "title": "6  Molecular Dynamic Simulations",
    "section": "",
    "text": "Minimization only aids in finding the local minimum of a function. Therefore, the structural features of molecules will need to be studied with various other tools (i.e., software) to find the global minimum.\nGiven the complexity of the potential energy surface (i.e., PES) of a real system, an efficient method of sapmling all possible phase spaces is necessary."
  },
  {
    "objectID": "wk6.html#a-brief-introduction-to-molecular-dynamics",
    "href": "wk6.html#a-brief-introduction-to-molecular-dynamics",
    "title": "6  Molecular Dynamic Simulations",
    "section": "6.1 A Brief Introduction to Molecular Dynamics",
    "text": "6.1 A Brief Introduction to Molecular Dynamics\nMoleuclar Dynamics (i.e., MD) is deterministic: the future state of a system is determined by its present state. The idea is to solve Newton’s equations of motion for a system of atoms that interact with each other via an energy function: a force field:\n\\[\\begin{equation}\n  -\\frac{dV}{dx} \\rightarrow F = ma \\rightarrow m\\frac{d^2x}{dt^2}\n\\end{equation}\\]\nWhere \\(x\\) represents the position of a molecule and \\(V(x)\\) the potential energy of a molecule.\nMD is typically used to compute equilibrium properties and transport properties (e.g., diffusion coefficients). MD is particularly well-suited to model macromolecular systems because of its generality.\n\n6.1.1 Historical Origins\nMD was introduced by Alder and Wainwright in the late 1950’s to study hard sphere interactions. Many important insights regarding simple liquid behaviors arose from their studies.\nRahman then carried out the first simulation using a realistic potential for liquid argon.\nThe first molecular dynamics simulation of a realistic system was done by Rahman and Stillinger during their liquid water simulation in 1974.\nThe first protein simulations were done in 1977 with the simulation of bovine pancreatic trypsin inhibitor (i.e., BPTI) by McCammon and Karplus.\nThe DNA double helix was done by Levitt in 1983. In today’s literature, one typically finds molecular dynamic simulations of protein-protein, protein-DNA, and lipid systems that address a variety of issues (including the thermodynamics of ligand binding and small protein folding).\nBecause of the above, there are many specialized systems for particular problems, including mixed quantum mechanical - classical simulations (that are employed to study enzymatic reactions).\nSimulations are typically used for experimental procedures (e.g., X-ray crystallography and NMR structure determination)."
  },
  {
    "objectID": "wk6.html#how-molecular-dynamics-work",
    "href": "wk6.html#how-molecular-dynamics-work",
    "title": "6  Molecular Dynamic Simulations",
    "section": "6.2 How Molecular Dynamics Work",
    "text": "6.2 How Molecular Dynamics Work\n\n\n\n\n\nSteps Underlying Molecular Dynamics\n\n\n\n\nThe derivatives of a macromolecular force field (e.g., OPLS) allows one to find the forces on each atom as a function of its position. A standard technique is to solve Newton’s methods numerically via some finite difference scheme.\nIn other terms, if the system is advanced by a small step \\(\\Delta t\\), the forces and velocities can be re-calculated. Provided that \\(\\Delta t\\) is sufficiently small, an approximation to the continuous equations of motion can be found.\n\n6.2.1 Verlet Leapfrog Method\n\n\n\n\n\nIllustration of the Verlet Leapfrog Method\n\n\n\n\nThis is one of the most popular methods and widely used integrators. Here, the positions and the velocities of particles are successively “leap-frogged” over one another using a force field’s acceleration:\n\\[\\begin{align}\n  \\vec{x}(t + \\Delta t) &= \\vec{x}(t) + \\vec{\\nu}\\left(t + \\frac{\\Delta t}{2}\\right)\\Delta t \\\\\n  \\vec{\\nu}\\left(t + \\frac{\\Delta t}{2}\\right) &= \\vec{\\nu}\\left(t - \\frac{\\Delta t}{2}\\right) + \\vec{a}(t)\\Delta t\n\\end{align}\\]\nThis scheme has a higher precision (of order \\(\\Delta t^4\\)) - this means that longer step times can be used for a given level of fluctuations.\nThis method also has low drift (provided that an appropriate time step and force cut-off is used)."
  },
  {
    "objectID": "wk6.html#tricks-of-the-trade",
    "href": "wk6.html#tricks-of-the-trade",
    "title": "6  Molecular Dynamic Simulations",
    "section": "6.3 Tricks of the Trade",
    "text": "6.3 Tricks of the Trade\nThere are a number of tricks that are centered around reducing the amount of effort in the calculation of atomic forces.\n\n6.3.1 Periodic Boundary Conditions\nPeriodic Boundary Conditions (i.e., PBCs) eliminates surface effect-edge molecules. The size of the system would need to be large enough to ensure that the surface only has a small influence on bulk properties.\nDuring a PBC, the simulation box is replicated throughout space to form an infinite lattice.\n\n\n\n\n\nInfinite Lattice of PBCs in Space\n\n\n\n\nWhen a particle leaves its boundary box, its periodic image in the other boxes also moves in the same orientation.\nAs a particle leaves the outer boundaries, it re-enters through the opposite face; the system has no surface at the outer boundaries.\n\n\n6.3.2 Distance Calculations\n\n\n\n\n\nIllustration of the Minimum Image Convention\n\n\n\n\nThe minimum image convention considers the nearest image of a given particle when calculating distances.\nThe maximum distance between two atoms in one dimension is half a box length.\n\n\n6.3.3 Non-Bonded Cutoffs\n\n\n\n\n\nIllustration of Non-Bonded Cutoffs with Increasing ‘n’\n\n\n\n\nIf a simulation system has \\(N\\) atoms, then the total number of interaction pairs is \\(\\displaystyle \\frac{N(N - 1)}{2} \\approx N^2\\). To reduce computational efforts, a cutoff is usually employed (i.e., non-bonded interactions within a distance are considered).\nThis simplification is valid for short-range interactions (e.g., van der Waals interactions), but caution should be utilized when dealing with long-range electrostatic interactions."
  },
  {
    "objectID": "wk6.html#molecular-dynamics-simulation-parameters",
    "href": "wk6.html#molecular-dynamics-simulation-parameters",
    "title": "6  Molecular Dynamic Simulations",
    "section": "6.4 Molecular Dynamics Simulation Parameters",
    "text": "6.4 Molecular Dynamics Simulation Parameters\n\n6.4.1 Time Steps\nToo short a time step and the phase space may be inefficiently sampled and too long a time step will cause the energy to fluctuate wildly (i.e., the simulation may “explode”).\nThe above instabilities are a consequence of atom motions being extrapolated into regions with exceedingly high potential energies.\nWhen simulating atomic fluids, the time step should be comparable to the mean time between collisions (i.e., about 5 femtoseconds).\nFor flexible molecules, the time step should be an order of magnitude less than the period of fastest motion (i.e., for a C-H bond, it’s around 10 femtoseconds, so about 1 femtosecond is good).\n\n\n6.4.2 Kinetic Energy and Temperature\nThe total kinetic energy for a system that has \\(N\\) particles is:\n\\[\\begin{equation}\n  E_{kin} = \\frac{1}{2}\\sum_{i = 1}^Nm_i\\nu_i^2\n\\end{equation}\\]\nFrom the above equation, the absolute temperature \\(T\\) is:\n\\[\\begin{equation}\n  \\frac{1}{2}N_{df}kT = E_{kin}\n\\end{equation}\\]\nWhere \\(k\\) is Boltzmann’s constant and \\(N_{df}\\) is the degrees of freedom which can be calculated using the formula \\(\\displaystyle N_{df} = 3N - N_{com}\\)\nIn this scenario, three degrees of freedom must be removed from \\(N_{com}\\) as the three center of mass velocities are constants of motion (which are typically set to zeroes).\n\n\n6.4.3 Pressure and Virial\nThe pressure \\(P\\) is the difference between kinetic energy \\(E_{kin}\\) and the virial \\(\\Xi\\):\n\\[\\begin{equation}\n  P = \\frac{2}{V}\\left(E_{kin} - \\Xi\\right)\n\\end{equation}\\]\nWhere \\(V\\) is the volume of the computational box and \\(P\\) is the scalar pressure - \\(P\\) can also be used for isotropic systems, in which case, \\(P\\) is denoted by \\(\\displaystyle P = \\frac{trace(P)}{3}\\)\n\\[\\begin{equation}\n  \\Xi = -\\frac{1}{2}\\sum_{i < j}\\vec{r}_{ij} \\bigotimes \\vec{F}_{ij}\n\\end{equation}\\]\nThe above equation is that for the virial tensor.\n\n\n6.4.4 Temperature Coupling\nTemperature coupling is utilized when one needs to determine the behavior of the system with regards to temperature (e.g., unfolding a protein). During such a system, the pressure \\(P\\) must be kept constant.\nThe Berendson coupling equation states that:\n\\[\\begin{align}\n  \\frac{dT}{dt} &= \\frac{T_0 - T}{\\tau_T} & \\frac{dP}{dt} = \\frac{P_0 - P}{\\tau_P}\n\\end{align}\\]\nTemperature coupling rescales velocity while pressure coupling rescales volume. When both the temperature and the pressure are controlled, the system is called isothermal-isobaric."
  },
  {
    "objectID": "wk7.html",
    "href": "wk7.html",
    "title": "7  Monte Carlo Simulations and Basic Statistical Mechanics",
    "section": "",
    "text": "“In a Monte Carlo simulation we attempt to study the system of a model for which change, or growth, does not proceed in some rigorously predefined fashion (e.g. according to Newton’s equations of motion) but rather in a stochastic manner which depends on a sequence of random numbers which is generated during the simulation.”\n– Landau and Binder\n\nA Monte Carlo simulation is a mathematical technique that is used to estimate the outcome of an uncertain event1.\n\n\nWhen a number is said to be pseudorandom, it means that there is some sort of algorithm (i.e., recursion) used to generate a sequence of numbers based on an initial number (i.e., the “seed”) \\(x_0\\).\nThe resultant set of numbers generated \\(\\{x_1, x_2, x_3, ...\\}\\) are independent of one another, uniform, and follow a long period.\n\n\nThis was an approached first used in 1948 by DH Lehmer to generate pseudorandom numbers. The process is as follows:\n\nMultiply the previous term by a constant \\(a\\).\nAdd the product in 1. to another constant \\(c\\).\nTake the modulus of the result with respect to a large number \\(M\\).\n\nTherefore, the next pseudorandom number generated \\(X_{i + 1}\\) is equivalent to \\((aX_i + c)\\mod(M)\\)\n\n\n\n\n\n\n\n\n\nA Circle on a Cartesian Plane\n\n\n\n\nThe area of the green circle \\(\\pi r^2\\) is proportional to the possibility of finding a point inside the object when the point is selected at random.\nIf we choose 1000 points in the above figure, 800 points will land inside the quarter circle.\n\n\n\n\n\nRandomly Plotted Points on a Cartesian Plane\n\n\n\n\nNonetheless, initially assume that \\(N_{in} = 0\\) - then, we perform the following \\(N\\) times:\n\nWe calculate two random numbers \\(x\\) and \\(y\\).\nIf \\(x^2 + y^2 < l\\), then \\(N_{in} = N_{in} + l\\)\n\nHence, we can argue that \\(\\displaystyle \\pi \\approx \\frac{4N_{in}}{N}\\)"
  },
  {
    "objectID": "wk7.html#metropolis-algorithm-and-markov-chains",
    "href": "wk7.html#metropolis-algorithm-and-markov-chains",
    "title": "7  Monte Carlo Simulations and Basic Statistical Mechanics",
    "section": "7.2 Metropolis Algorithm and Markov Chains",
    "text": "7.2 Metropolis Algorithm and Markov Chains\nIn canonical ensembles, the probability density function is proportional to the Boltzmann factor via the following equation:\n\\[\\begin{equation}\n  \\rho(X) \\alpha \\exp(-\\beta E(X))\n\\end{equation}\\]\nWhere \\(\\displaystyle \\beta = \\frac{1}{k_BT}\\). To calculate a physical quantity \\(A\\) for an ensemble, we would need to calculate the value of the following integral:\n\\[\\begin{equation}\n  A = \\int \\rho(X) A(X) dX\n\\end{equation}\\]\nUsing Monte Carlo Sampling, the integral becomes:\n\\[\\begin{equation}\n  A = \\lim_{m \\rightarrow \\infty}\\sum_{i = 1}^MA(X_i)\n\\end{equation}\\]\n\n7.2.1 Metropolis Algorithm\nThis algorithm - devised in 1953 - is an efficient and simple procedure for the canonical ensemble.\nFor \\(i = 0, 1, 2, ...\\) given \\(X_0\\), we do the following:\n\nGenerate \\(X_{i + 1}'\\) from \\(X_i\\) using a perturbation technique\nCompute \\(\\Delta E = E(X_{i + 1}' - E(X_i)\\)\nIf \\(\\Delta E < 0\\) (i.e., a downhill move), \\(X_{i + 1} = X'_{i + 1}\\), else \\(\\rho = \\exp(-\\beta \\Delta E)\\) - if \\(\\rho\\) is larger than a random number, then \\(X_{i + 1} = X'_{i + 1}\\).\nThe above three steps repeat.\n\n\n\n7.2.2 Markov Chains\nThe metropolis algorithm generates a chain of molecule states \\(\\{X_1, X_2, X_3, ...\\}\\). States that have a lower energy are always accepted, but states with higher energies have a nonzero probability of acceptance too.\nBecause of this, sampling typically occurs in regions of lower energies, but the system can escape to other energy basins by jumping over large energy barriers.\n\n7.2.2.1 BOSS Program\nThe Biochemical and Organic Simulation System (i.e., BOSS) program is a general purpose molecular modeling system that performs molecular mechanics, monte carlo simulations, and other quantum mechanical calculations.\nA monte carlo simulation generates a new configuration via random motions. This difference in energy between the new and the old set is used as a selection criterion in the Metropolis algorithm - this procedure is then repeated and uses internal coordinates\n\n\n7.2.2.2 Z Matrices\nA Z-matrix is used to represent a system made out of atoms - it is also known as an internal coordinate representation.\n\n\n\n\n\nZ-Matrix for Methane\n\n\n\n\nZ-matrices provide a description of each atom in a molecule in term of its atomic number, its bond length, its bond angle, and its dihedral angle (i.e., the internal coordinates).\nThe first line of the above Z-matrix contains a carbon atom (i.e., atom 1).\nThe second line contains a hydrogen atom (i.e., atom 2) the “H 1 1.089000” represents the distance between the hydrogen atom in question and the first atom (i.e., the carbon atom mentioned in the preceding paragraph).\nThe third line states that the bond angle between the first, the second, and the third atom is 109.471 degrees.\nThe fourth line states that the dihedral angle between the current atom and the other three atoms is 120 degrees.\n\n\n\n7.2.3 Comparing Molecular Dynamics and Molecular Computation\n\n\n\n\n\nComparisons Between Molecular Dynamics and Molecular Computations"
  },
  {
    "objectID": "wk7.html#statistical-mechanics",
    "href": "wk7.html#statistical-mechanics",
    "title": "7  Monte Carlo Simulations and Basic Statistical Mechanics",
    "section": "7.3 Statistical Mechanics",
    "text": "7.3 Statistical Mechanics\nThe mechanical or microscopic state of a system is given by its atomic positions \\(q\\) and its momenta \\(p(m_iv_i)\\). The latter can also be considered as coordinates in a multidimensional space called the phase space.\nFor a system with \\(N\\) particles, the phase space has \\(6N\\) dimensions. A single point in this space describes the system’s state.\nThe thermodynamic or macroscopic state of a system is defined by a small set of parameters - for instance, the temperature \\(T\\), the pressure \\(P\\), and the number of particles \\(P\\).\n\n7.3.1 Types of Ensembles\n\n\n\n\n\nIllustration of an Ensemble\n\n\n\n\nAn ensemble is a collection of possible systems (with different microscopic states), but have an identical macroscopic or thermodynamic state.\nThere are several states examined in BS3008:\n\nMicrocanonical Ensemble (NVE)\nThe thermodynamical state is characterized by a fixed amount of atoms \\(N\\), a fixed volume \\(V\\), and a fixed energy \\(E\\). This is an isolated system.\nCanonical Ensemble (NVT)\nThe thermodynamical state has a fixed number of atoms and a fixed volume and temperature.\nIsobaric-Isothermal Ensemble (NPT)\nThe ensemble has a constant amount of atoms and a constant pressure and temperature.\nGrand Canonical Ensemble (\\(\\mu\\)VT)\nThe thermodynamic state has a constant volume, temperature, and chemical potential.\n\n\n\n7.3.2 Entropy\n\\[\\begin{equation}\n  S = -k_B \\sum_iP_i^B \\ln(P_i^B)\n\\end{equation}\\]\nThe entropy of a system is also the ensemble average.\n\n\n7.3.3 Potential of Mean Force\n\n\n\n\n\nEnergy of a Molecule\n\n\n\n\nThe potential of mean force (i.e., PMF) is the free energy of one or more coordinates. It is defined from the average distribution function:\n\\[\\begin{align}\n  w(x) &= w(x') - k_BT \\cdot \\ln\\left(\\frac{\\rho(x)}{\\rho(x')}\\right) \\\\\n  \\rho(x) &= \\sum_{i \\in data}\\delta(x - x_i)\n\\end{align}\\]\nWhere \\(w\\) is the PMF,\\(x\\) is the coordinate, and \\(x'\\) is a reference point.\n\n7.3.3.1 Procedure for Calculating PMF\nOnce a MD or a MC study has been performed:\n\n\\(\\phi\\) and \\(\\psi\\) can be calculated from trajectories.\nDivide the range of \\(\\phi\\) as \\(x\\) into \\(N\\) bins.\nCount the number in each bin \\(n(x)\\).\nCalculate the free energy difference between two bins or two states via the equation \\(\\displaystyle F = -k_BT\\ln\\left(\\frac{n(x_!)}{n(x_2)}\\right)\\)"
  },
  {
    "objectID": "wk7.html#ergodic-hypothesis",
    "href": "wk7.html#ergodic-hypothesis",
    "title": "7  Monte Carlo Simulations and Basic Statistical Mechanics",
    "section": "7.4 Ergodic Hypothesis",
    "text": "7.4 Ergodic Hypothesis\nIn reality, the summation of different states in an ensemble is super tough as one must calculate the possible states of a system.\nIn a molecular dynamic simulation, the points in an ensemble are calculated sequentially in time, so to calculate an average, the simulation must pass through all possible states that correspond to the particular thermodynamic constraints.\nAnother way also involves determining a time average of \\(A\\):\n\\[\\begin{equation}\n  A_{time} = \\frac{1}{\\tau}\\sum_{r \\rightarrow \\infty}A(p^N(t), r^N(t)) \\approx \\sum_{t = 1}^MA(t)\n\\end{equation}\\]\nWhere \\(t\\) is the simulation time, \\(M\\) the number of time steps in the simulation, and \\(A(p^N, r^N)\\) is the instantaneous value of \\(A\\).\n\n7.4.1 Dilemma\nThe dilemma of the above is that a molecular dynamics simulation can calculate time averages, but the experimental observables are assumed to be ensemble averages.\n\\[\\begin{equation}\n  A_{ensemble} = A_{time}\n\\end{equation}\\]\nHence, the ergodic hypothesis states that the time average is equivalent to the ensemble average - in other terms, the above equation."
  },
  {
    "objectID": "wk7.html#replica-exchange-simulations",
    "href": "wk7.html#replica-exchange-simulations",
    "title": "7  Monte Carlo Simulations and Basic Statistical Mechanics",
    "section": "7.5 Replica Exchange Simulations",
    "text": "7.5 Replica Exchange Simulations\n\n\n\n\n\nReplica Exchange Simulations Illustrated\n\n\n\n\nA replica exchange simulation is an advanced sampling technique that involves performing numerous molecular dynamics simulations on many copies of a system with a different value for some control parameter.\nThe point behind a replica exchange simulation is to ensure that high-temperature configurations can overcome energy barriers on a potential energy surface.\nWhen a replica exchange simulation is done at a low temperature, the sampling represent the lowest energy minima while the high temperature ones are capable of sampling the entire surface. This is superbly advantageous over Monte Carlo or traditional molecular dynamics simulations as both those methods tend to be on the slower side of things."
  },
  {
    "objectID": "wk8.html",
    "href": "wk8.html",
    "title": "8  Docking and Drug Discovery",
    "section": "",
    "text": "Docking and Scoring\nDocking is the act of placing a ligand (i.e., a small molecule) into the binding site of a receptor in an appropriate manner so that it may interact with the receptor.\nScoring is the evaluation of the ligand-receptor interactions in a way that may distinguish between experimentally-observed results and also estimate the binding affinity.\nDocking is done to discover how best to optimize drug binding to their targets as drug discovery costs are quite high (i.e. about 800 million dollars just to go through 10000 compounds in eight to 14 years)."
  },
  {
    "objectID": "wk8.html#determinants-for-binding",
    "href": "wk8.html#determinants-for-binding",
    "title": "8  Docking and Drug Discovery",
    "section": "8.1 Determinants for Binding",
    "text": "8.1 Determinants for Binding\nBiding is a complex process that is controlled by several factors, including:\n\nInteraction energies between two different energies.\nDesolvation and solvation energies associated with interacting molecules.\nEntropic factors that occur upon binding.\n\n\n8.1.1 “Lock and Key” Principle\n\n“The specificity of an enzyme (the lock) for its substrate (the key) arises from their geometrically complementary shapes.”\n– Emil Fischer (1894)\n\nThis model proposes that a molecule fits into the enzyme like a key fitting into a lock.\n\n\n8.1.2 Induced Fit Model\n\n\n\n\n\nIllustration of the Induced Fit Model\n\n\n\n\nProteins in their apo conformations have different shapes in their holo states. When a ligand binds to the enzyme’s active site, this induces a sort of conformational change within the enzyme itself.\nThis model is supported by X-ray structures of the same protein in the apo (i.e., open) form without the ligand’s presence and in thte holo (i.e., closed) form with the ligand binding.\n\n\n8.1.3 Conformational Selection\n\n\n\n\n\nConformational Selection Model\n\n\n\n\nPrior to the binding interaction, the protein is an ensemble of conformations that exist in dynamic equilibrium. The binding partner (i.e., ligand) then interacts with a weakly populated, higher-energy conformation, causing the equilibrium to shift in favor of the selected conformation.\n\n\n8.1.4 Protein-Ligand Binding Process\n\n\n\n\n\nMultiple States in Ligand Binding\n\n\n\n\nProtein-ligand binding is a complex process between:\n\nAn ensemble of solvated ligand conformations\nA sovlated receptor binding site\nA solvated receptor-ligand complex\n\nBinding free energies may involve:\n\nEnthalpic components (e.g., breaking and forming new hydrogen bonds and forming hydrophobic components)\nEntropic components (e.g., loss of conformational flexibility)\nDesolvation effects"
  },
  {
    "objectID": "wk8.html#components-of-docking",
    "href": "wk8.html#components-of-docking",
    "title": "8  Docking and Drug Discovery",
    "section": "8.2 Components of Docking",
    "text": "8.2 Components of Docking\n\n\n\n\n\nThree Main Components of Docking\n\n\n\n\nThe above graphic lists three main components of docking that BS3008 covers.\n\n8.2.1 Binding Site Descriptions\nThe Protein Data Bank (i.e., PDB) is a publicly available database that contains proteins or enzymes.\nHowever, Davis et al. notes the following limitations of experimental structures (in general):\n\nLocations of hydrogen atoms, water molecules, and metal ions.\nIdentities and locations of heavy atoms\nConformational flexibility of proteins\n\nBinding sites can be described in terms of atomic coordinates, volume, points & distances, and various properties such as electrostatic interactions and atom types.\nHowever, Davis et al. notes several limitations of experimental structures:\n\nThe locations of metal ions, hydrogen ions, and water molecules may be off.\nThe identities of the metal ions may be off in a biomolecule’s PDB file.\nConformational flexibility of proteins may be off.\n\n\n\n8.2.2 Drug, Chemical, and Structural Space\nProf. Mu lists some resources for drug and chemical structures:\n\nThe MDL Drug Data Report (i.e., MDDR) has more than 147000 entries and the Comprehensive Medicinal Chemistry (i.e., CMC) more than 8600 entries.\nThe Available Chemical Directory has about three million entries.\nBeilstein, Chemical Abstract Services (i.e., CAS), and SciFinder - both literature finding services\nCambridge Structural Database (i.e., CSD) - this has about three million X-ray crystal structures for more than 264000 different compounds and more than 12800 organic structures.\nCorporate databases also a have a few million entries.\n\n\n\n8.2.3 3D Structural Information and Ligand Descriptors\nProf. Mu continues listing some more resources in this section:\n\n2D to 3D Software\nIncluding CORINA, OMEGA, CONCORD, MM2/3, WIZARD, and COBRA.\nCSD\nIt contains sizes of less than 0.1 Angstrom for small molecules, but may not be the bound conformation to the receptor in question.\nPDB\nThis resource has about 6000 entries of ligand-bound protein structures."
  },
  {
    "objectID": "wk8.html#sampling-the-configuration-space-of-the-ligand-receptor-complex",
    "href": "wk8.html#sampling-the-configuration-space-of-the-ligand-receptor-complex",
    "title": "8  Docking and Drug Discovery",
    "section": "8.3 Sampling the Configuration Space of the Ligand-Receptor Complex",
    "text": "8.3 Sampling the Configuration Space of the Ligand-Receptor Complex\n\n\n\n\n\nComparisions Between a Systematic and a Stochastic Complex\n\n\n\n\nThe above graphic lists some differences between a stochastic and a systematic complex.\nA sampling requires the following parameters:\n\nPosition or Translation\nIn other terms, the three Cartesian coordinates \\(x\\), \\(y\\) and \\(z\\).\nOrientations\nThis refers to the derivatives of the above Cartesian coordinates \\(dx\\), \\(dy\\) and \\(dz\\).\nRotatable Bonds or Torsions\nThis is represented as \\(tor_1\\), \\(tor_2\\), \\(tor_n\\), and so on (where \\(n\\) is some positive integer).\nTotal DOF (i.e., dimensionality)\nThis is given by the formula \\(D = 3 + 3 + n\\).\n\n\n8.3.1 Estimating Search Spaces\nA typical ligand binding pocket is about 103 Angstroms big. A typical ligand has four rotational bonds.\nThe granularity has an angle sampling of 10 degrees and a translation of a 0.5 Angstrom grid. Hence, the total number of possible sampling configurations is about \\(20^3 \\cdot 36^3 \\cdot 36^4 \\approx 6 \\times 10^{14}\\).\nGiven that a computer can process about 1000 conformations per second, a search space this size could easily result in 20000 years per ligand.\nConsequently, other methods - such as descriptor matching (which uses pattern-recognizing methods to match ligands and receptor sites), molecular dynamics, monte carlo simulations, genetic algorithms, similarities, and fragment-based approaches - must be utilized.\nSome examples of descriptor matching methods include:\n\nDistance-compatibility graphs in the DOCK program\nInteraction site matching in the LUDI program\nPose clustering and triplet matching in the FlexX program\nShape matching in the FRED program\nVector matching in the CAVEAT program\nSteric effects matching in the CLIX program\nShape chemical complimentarity in the SANDOCK program\nSurface complimentarity in the LIGIN program\nH-bond matching in the ADAM program\n\nHowever, the following disadvantages must be noted:\n\nOne can never truly sample the entire conformation and the configuration space - it is simply too large.\nOne cannot ignore the conformational flexibility of the ligand and the receptor.\nThere is no one “best” method or general solution for describing and matching molecular shapes. Shape alone is not a good indicator of a low-energy conformation in a ligand-receptor complex.\n\n\n8.3.1.1 Method 1: Clique Search\nThis is a descriptor-matching method that uses distance-compatibility graphs in the DOCK program:\n\n\n\n\n\nA Sample Distance-Compatibility Graph\n\n\n\n\nA Distance-Compatibility graph is a graph where each node represents possible matches and each edge a pair of compatible nodes.\nA clique in graph theory is a subgraph that is fully connected. There are fast algorithms that can optimize this problem.\n\n\n8.3.1.2 Method 2: Molecular Dynamics (i.e., MD) and Monte Carlo (i.e., MC) Simulations\nThe two major components of this system are the energy evaluations and the description of the energies of freedom.\nLocal movement of the atoms are preferred - this is random in a Monte Carlo simulation due to forces in a molecular dynamics setup.\nHowever, both MD and MC are time consuming as not only do both approaches start from a “starting orientation”, but multiple simulations with different “starting orientations” must also be performed to get a statistically significant result.\nLarger steps are typically used for speed in a MD simulation.\n\n8.3.1.2.1 Using a Grid Map\nA grid map is a representation of a macromolecule (i.e., a regular orthogonal lattice of points). A man has one ligand atom type.\n\n\n\n\n\nA Sample Grid Map Generated Using AutoDock\n\n\n\n\nAll AutoDock-generated grid maps use trilinear interpolation. Non-bonded energies are pre-calculated.\nGrid maps save time - they are a 100 times faster than traditional non-bonded list methods.\n\n\n8.3.1.2.2 MC-Based Dockings\nThe good part about using a MC-based approach is that prior information does not need to be known - it is able to “step over an energy barrier”.\nSimulated Annealing is used in the program DockVision and Affinity.\n\n\n8.3.1.2.3 Simulated Annealing (i.e., SA)\nSimulated Annealing is the generalization of a Monte Carlo method for examining the equations of state and frozen states of n-body systems. This process is based on how liquids freeze or how metals recrystalize.\nIn an annealing process, the material is initially at a high temperature and is disordered. It is slowly cooled over time (to the ground state \\(T = 0\\)) so that it can roughly reach thermodynamic equilibrium.\nIf the initial temperature of the system is too low or if the cooling is not done properly, then the system may form defects or lose metstable states (i.e., be trapped in a local minimum energy state).\n\n\n\n8.3.1.3 Fragment-Based Methods\n\n\n\n\n\nIllustration of a Fragment-Based Method\n\n\n\n\nThe identification and the placement of a base or an anchor fragment is critical. Energy optimization is also important here.\n\n8.3.1.3.1 Fragment-Based Lead Discovery\n\n\n\n\n\nFragment-Based Drug Discovery Part I\n\n\n\n\nThe high-throughput screening (i.e., HTS) hit is large and makes surface contact with the receptor without forming high-quality interactions in key pockets.\nThe affinity is spread throughout the entire molecule and, in the absence of structural information, the medicinal chemist does not know which areas of the molecule to focus on during hit optimization.\nThis is in contrast to the schematic on right side, in which fragment 1 is much smaller, makes high-quality contacts with the receptor and has relatively weak affinity. It has been shown that such fragments can often be built up into attractive leads with the aid of structural information.\n\n\n\n\n\nFragment-Based Drug Discovery Graph\n\n\n\n\nThe figure shows graphically a broad generalization of the range of molecular mass and potency for high-throughput screening (i.e., HTS) hits and fragments, superimposed on the typical requirements for leads, drug candidates and oral drugs using the same criteria.\nFragment hits will have an Mr in the range 120–250 and low potency (mM–30 \\(\\mu\\)M); HTS hits will have a much broader range of Mr (perhaps 250–600) and tend to be in the low-\\(\\mu\\)M to high-nM potency range.\n\n\n\n8.3.1.4 Genetic Algorithm Docking\nIn this algorithm, degrees of freedoms are encoded as genes or binary strings; this algorithm also requires the generation of an initial population.\nAfter each reproduction cycle, the binary strings are then translated back to their candidate states (i.e., Cartesian coordinates) - the fitness of these strings are also evaluated by an appropriate function.\nCandidates with a better fitness have a higher probability to partake in the next reproduction cycle - in the end, only states with the highest fitnesses will survive.\n\n8.3.1.4.1 An Example:\nA coolection of genes (i.e., a chromosome) is assigned a fitness value depending on a scoring function. There are two such genetic operators:\n\nMutation\nThis changes the value of a gene.\nCrossovers\nThese exchange a set of genes from one parent chromosome to another.\n\nA fitness function is then used to decide which configurations (i.e., individuals) survive and produce offspring for the next iteration of optimization.\n\n\n\n8.3.1.5 Multiple Methods\nSometimes, more than one docking protocol can be combined to increase a protocol’s effectiveness.\nTypically, a computationally-inexpensive method, followed by a time-consuming, yet more accurate method is used to generate a final docking solution."
  },
  {
    "objectID": "wk9.html",
    "href": "wk9.html",
    "title": "9  Nonbonded Computations and Data Analysis",
    "section": "",
    "text": "A Computational Bottleneck\nThe rapid, quadratic growth in computational time when all non-bonded interactions increase are summed - this is in contrast to the linear growth shown with “cutoff” procedures."
  },
  {
    "objectID": "wk9.html#spherical-cutoff-techniques",
    "href": "wk9.html#spherical-cutoff-techniques",
    "title": "9  Nonbonded Computations and Data Analysis",
    "section": "9.1 Spherical Cutoff Techniques",
    "text": "9.1 Spherical Cutoff Techniques\n\n\n\n\n\nDifferent Spherical Cutoff Techniques Illustrated\n\n\n\n\nBS3008 lists three basic categories of cutoff techniques. All of these approaches set a distance-dependent nonbonded function to zero beyond some distance \\(r = b\\). However, distances less than \\(b\\) are treated differently:\n\nTruncation\nThis is the simplest. Values at a distance \\(b\\) are zeroes, but otherwise unchanged.\nSwitching Schemes\nValues \\(a\\) at a nonzero value are changed when \\(a < b\\), but values for \\(r < a\\) are unchanged.\nShift Functions\nThe nonbonded function is gradually altered for all \\(r < b\\).\n\nThe above three categories can be applied to the force function’s energy of the nonbonded potentials (i.e., van der Waals or electrostatic); the following schemes or cutoffs can be used:\n\nAtom-based or group-based schemes\nIn group-based schemes, distance thresholds are applied to distances between group members (e.g., charge groups in a GROMACS topology file).\nGroup-based cutoffs\nThese can maintain better charges associated with entire residues. They can avoid potential instabilities in the energy or force that arise when a subset of atoms of a particular residue is altered.\n\nCare should be applied to specify the distance parameter between the distance parameters \\(a\\) and \\(b\\).\n\n9.1.1 Guidelines for Cutoff Functions\nProf. Mu lists some guidelines when choosing to use cutoff functions:\n\nShort-range energies and forces should be altered as little as possible.\nEnergies should be gradually altered over time.\nThe cutoff approach chosen should not introduce large forces around the cutoff region. This is important for molecular dynamics simulations.\nOn the topic of 3), it is important that the cutoff energy alters the energy in a way that conserves energy.\n\n\n\n9.1.2 Highly-Charged Systems\n\n\n\n\n\nA Highly-Charged System\n\n\n\n\nThe above figure shows the time-evolution of a RMS deviation from the initial structure (i.e., the top graph) - d(CCAACGTTGG)2 and the bottom structure GGAUUUCGGUCC. The dotted lines represent CUT and CUTSS simulations.\nCUT is a charge group that’s based on a truncation cutoff. CUTSS is a group that’s based on a truncation cutoff with complete evaluation of all solute-solute interactions.\n\n9.1.2.1 Long-Ranged PME\nThe total Coulomb energy that corresponds to a system in an infinite periodic domain is:\n\\[\\begin{align}\n  E_{coul} &= \\frac{1}{2}\\sum_{i, j = 1}\\sum_{images |n|}\\frac{q_iq_j}{|r_{ij} + n|} = \\frac{1}{2}\\sum_{j = 1}q_j\\Phi(x_j) \\\\\n  \\Phi(x_j) &= \\sum_{i = 1}\\sum_{images |n|}\\frac{q_i}{|r_{ij} + n|}\n\\end{align}\\]\nThe sum in the above equation is convergent as:\n\\[\\begin{align}\n  \\sum_{n = 1}^\\infty \\frac{1}{n} &= 1 + \\left(\\frac{1}{2} + \\frac{1}{3}\\right) + \\left(\\frac{1}{4} + \\frac{1}{5} + \\frac{1}{6} + \\frac{1}{7}\\right) \\\\\n  &> 1 + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2} + \\frac{1}{2}\n\\end{align}\\]\n\n\n9.1.2.2 Ewald’s Trick\n\n\n\n\n\nShape of the erf(x) function\n\n\n\n\nTo convert the above sum into a sum of two absolutely and rapidly converging series, each point is represented as a Gaussian charge density.\nThe Ewald sum is:\n\\[\\begin{align}\n  \\Phi(r) &= \\frac{1}{r} = \\Phi_{real}(r) + \\Phi_{recip}(r) \\\\\n  \\Phi_{real} &= \\frac{1}{r} - \\frac{erf (\\beta r)}{r} \\\\\n  \\Phi_{recip}(r) &= \\frac{erf(\\beta r)}{r}\n\\end{align}\\]\nThe variable \\(\\beta\\) in the above equations control the width of the distribution and the rate of convergence of the sum.\n\\[\\begin{equation}\n  \\rho_{G_j}(x) = -q_j\\left(\\frac{\\beta}{\\sqrt{\\pi}}\\right)^3\\exp[-\\beta^2|x|^2]\n\\end{equation}\\]\nThe second breakthough in the trick came from the observation that the trigonometric functions in the Fourier series used to represent the reciprocal-space term can be evlauated via smooth interpolation of the potential over a grid.\nThis resulting particle-mesh Ewald (i.e., PME) method runs in \\(O(n\\log(n))\\) time1."
  },
  {
    "objectID": "wk9.html#analyzing-molecular-dynamics-data",
    "href": "wk9.html#analyzing-molecular-dynamics-data",
    "title": "9  Nonbonded Computations and Data Analysis",
    "section": "9.2 Analyzing Molecular Dynamics Data",
    "text": "9.2 Analyzing Molecular Dynamics Data\nProf. Mu lists some approaches in this section of this week’s lecture:\n\n9.2.1 End-to-End Distance\n\n\n\n\n\nAn Illustration of the End-to-End Distance\n\n\n\n\nThis is the distance between the first and last segment of a biopolymer (i.e., \\(d\\) in the above graphic).\nThis is most suitable for describing linear polymers.\n\n\n9.2.2 Radius of Gyration\n\n\n\n\n\nAn Illustration of the Gyration Radius\n\n\n\n\nThis is the mass-weighted average distance of selected atoms from their center of mass and is given by:\n\\[\\begin{equation}\n  Rg = \\sqrt{\\frac{\\sum_{i = 1}^N m_i(r_i - r_{com})^2}{\\sum_{i = 1}^N m_i}}\n\\end{equation}\\]\nThis is most suitable for describing branched chains with a large amount of ends.\n\n\n9.2.3 Mean Square Distance Fluctuation\n\\[\\begin{align}\n  <\\delta r^2> &= \\frac{\\sum_{t = 1}^k(r_t - r_{average})^2}{K} \\\\\n  r_{average} &= \\frac{\\sum_{t = 1}^K r_t}{K}\n\\end{align}\\]\n\\(K\\) represents the molecular dynamics simulation’s time step. This describes the size of the atoms’ fluctuations around their equilibrium positions.\n\n\n9.2.4 Debye-Waller (i.e., B or Temperature) Factor\nThe Debye-Waller factor \\(B_a\\) is given by:\n\\[\\begin{align}\n  B_a &= \\frac{8}{3}\\pi^2<\\delta r_a^2> \\\\\n  \\delta r_a &= r_a - r_{a, average}\n\\end{align}\\]\n\\(B_a\\) describes the reduction of intensity of Bragg scattering due to atomic motion about their equilibrium position. The atomic scattering factor is:\n\\[\\begin{equation}\n  f = f_0\\exp\\left[-B\\left(\\frac{\\sin\\phi}{\\lambda}\\right)^2\\right]\n\\end{equation}\\]\n\\(f\\) does not vanish even at \\(T = 0\\) because of atomic motion.\n\n\n9.2.5 Root Mean Squared Deviation\nThis is given by :\n\\[\\begin{equation}\n  RMSD(t) = \\sqrt{\\frac{\\sum_{i = 1}^N m_i\\left[r_i(t) - r_i^{reference}\\right]}{M}}\n\\end{equation}\\]\nWhere \\(N\\) is the total amount of atoms, \\(m_i\\) the mass of the atom in question, and \\(M\\) is the total mass of the molecule.\nThie describes the “distance” between the conformation at a time \\(t\\) and that of a reference structure (i.e., how similar they are).\n\n\n9.2.6 Solvent-Accessible Area (i.e., ASA)\n\n\n\n\n\nSolvent-Accessible Area\n\n\n\n\nThe ASA is the area over which contact between a protein and its solvent can occur."
  },
  {
    "objectID": "wk9.html#protein-flexibilities-and-normal-modes",
    "href": "wk9.html#protein-flexibilities-and-normal-modes",
    "title": "9  Nonbonded Computations and Data Analysis",
    "section": "9.3 Protein Flexibilities and Normal Modes",
    "text": "9.3 Protein Flexibilities and Normal Modes\n\n\n\n\n\nProtein Flexibility Illustrated\n\n\n\n\nOver half of the 3800 known protein movements can be modelled using two low-frequency normal modes.\n\n\n\n\n\nExamples of Normal Modes\n\n\n\n\nA normal mode is an oscillating pattern of motion where all parts of the system move sinusoidally with the same frequency.\nThese “frequencies” are known as a normal mode’s natural frequencies or resonant frequencies.\n\n9.3.1 Harmonic Approximations\n\n\n\n\n\nIllustration of a Harmonic Potential\n\n\n\n\nProf. Mu lists the following methods:\n\nPerform energy or geometry minimization\nCalculate the Hessian matrix \\(\\displaystyle K_{ij} = \\frac{\\partial E}{\\partial x_i \\partial x_j}\\)\nDiagonalize the Hessian to find its eigenvalues and eigenvectors.\n\nThe eigenvectors and eigenvalues of 3) indicate the mode of action and the frequency respectively."
  },
  {
    "objectID": "lab1.html",
    "href": "lab1.html",
    "title": "10  PDB Files and PyMOL Visualizations",
    "section": "",
    "text": "If you have taken BS1005: Biochemistry I, then the contents of this practical will be relatively straightforward1.\nThis lab aims to provide a gentle introduction to PDB files and also PyMOL."
  },
  {
    "objectID": "lab1.html#pdb-files",
    "href": "lab1.html#pdb-files",
    "title": "10  PDB Files and PyMOL Visualizations",
    "section": "10.1 PDB Files",
    "text": "10.1 PDB Files\nThe first part of the lab examines the structure of a PDB typical PDB file. The later part of this lab then requires you to write your own PDB file for a water molecule (before opening it up in PyMOL to ensure that you have done it correctly.)\nThe Protein Data Bank (i.e., PDB) is an initiative by the Brookhaven National Laboratory that stores three-dimensional data of biological molecules (i.e., biomolecules). A considerable amount of information has since been uploaded to the PDB from various fields in Biology, including but not limited to genomics, proteonomics, and structural biology.\n\n10.1.1 What is a PDB File?\nA PDB file is a plain text document that contains metainformation about a biomolecule - for instance, its atoms, its side chains, and its amino acid residues.\nThe PDB also has official documentation on the structure of its files that you can view for reference.\n\n\n10.1.2 Points to Note\nAlthough a typical PDB file contains numerous section and record types, BS3008 only focuses on a few of these records (and their important parts):\n\nThe ATOM Record\nThis is used to define atoms in a PDB file. With this record, the file writer can also define the positions of the atoms (in a three-dimensional space), define side-chain groups, and also define amino acid residues.\nNote that all coordinates of length will be in Angstroms in a PDB file.\nB-factors\nThis is also known as the temperature factor. B-factors describe how much an atom’s placement differs from its average values - the higher the B-factor, the higher its displacement.\nAreas with high B-factors are usually red (i.e., hot) and vice versa.\nOccupancy\nThis parameter is associated with different conformations of a biomolecule.\nDepending on how many conformations there are available, the occupancy may be less than one (but whatever the case, the values of all occupancices will always add up to one).\n\n\n\n10.1.3 Making a PDB File for a Water Molecule\nA water molecule has two hydrogen atoms and one oxygen atom. Its O-H bond length is 0.957 Angstroms and its H-O-H bond angle is \\(109^\\circ\\).\nHence, first set the Oxygen atom to the origin (0, 0, 0) using an ATOM record2:\n         1         2         3         4         5         6         7\n1234567890123456789012345678901234567890123456789012345678901234567890123456789\nATOM     1   O      A    1      0.000   0.000    0.000  1.00 0.00            O\nThereafter, add in the first hydrogen atom at the coordinates (0.957, 0, 0) using another ATOM record. It not necessary to use the aforementioned coordinates - (0, 0.957, 0) and (0, 0, 0.957) also work:\n         1         2         3         4         5         6         7\n1234567890123456789012345678901234567890123456789012345678901234567890123456789\nATOM     1   O      A    1      0.000   0.000    0.000  1.00 0.00            O\nATOM     2   H      A    1      0.957   0.000    0.000  1.00 0.00            H\nBasic trigonometry can then be used to discover the coordinates of the final hydrogen atom. In this case:\n\\[\\begin{align}\n  x &= -\\cos(71^\\circ) * 0.957 \\\\\n  y &= \\sin(71^\\circ) * 0.957\n\\end{align}\\]\nDoing so should yield a pair of coordinates \\((-0.312, 0.905)\\). The final pair of coordinates (with TER and END records) should be:\n         1         2         3         4         5         6         7\n1234567890123456789012345678901234567890123456789012345678901234567890123456789\nATOM     1   O      A    1      0.000   0.000    0.000  1.00 0.00            O\nATOM     2   H      A    1      0.957   0.000    0.000  1.00 0.00            H\nATOM     3   H      A    1     -0.312   0.957    0.000  1.00 0.00            H\nTER      4\nEND \nYou can open your PDB file in PyMOL to verify that your PDB file is correct."
  },
  {
    "objectID": "lab1.html#visualizing-molecules-in-pymol",
    "href": "lab1.html#visualizing-molecules-in-pymol",
    "title": "10  PDB Files and PyMOL Visualizations",
    "section": "10.2 Visualizing Molecules in PyMOL",
    "text": "10.2 Visualizing Molecules in PyMOL\nPyMOL is an open-source software for visualizing molecules and measuring their various properties. These “molecules” are often stored in a PDB file format (hence the reason why the first portion of the practical deals with PDB files).\n         1         2         3         4         5         6         7         8\n12345678901234567890123456789012345678901234567890123456789012345678901234567890\nATOM     38  N       A        -33.869   10.617   7.317  1.00 76.26           N\nATOM     39  CA      A        -34.134    9.234   6.904  1.00 74.56           C\nATOM     40  C       A        -33.089    8.813   5.875  1.00 73.03           C\nATOM     41  O       A        -32.729    9.593   4.989  1.00 72.13           O\nATOM     42  CB      A        -35.552    9.101   6.317  1.00 75.48           C\nATOM     43  CG      A        -36.647    9.421   7.338  1.00 77.63           C\nATOM     44  OD1     A        -36.667    8.874   8.452  1.00 81.93           O\nATOM     45  ND2     A        -37.570   10.304   6.961  1.00 75.30           N\nATOM     46  N       A        -32.604    7.582   5.965  1.00 74.10           N\nATOM     47  CA      A        -31.570    7.168   5.019  1.00 77.48           C\nATOM     48  C       A        -32.043    6.300   3.846  1.00 73.71           C\nATOM     49  O       A        -31.538    5.201   3.613  1.00 76.65           O\nATOM     50  CB      A        -30.416    6.504   5.793  1.00 83.44           C\nATOM     51  CG      A        -29.901    7.343   6.934  1.00 90.57           C\nATOM     52  ND1     A        -29.361    8.601   6.754  1.00 92.16           N\nATOM     53  CD2     A        -29.899    7.125   8.275  1.00 92.50           C\nATOM     54  CE1     A        -29.051    9.123   7.930  1.00 91.80           C\nATOM     55  NE2     A        -29.369    8.247   8.871  1.00 92.32           N\nATOM     56  N       A        -33.001    6.831   3.089  1.00 67.38           N\nATOM     57  CA      A        -33.551    6.148   1.924  1.00 59.99           C\nATOM     58  C       A        -33.046    6.785   0.618  1.00 55.78           C\nATOM     59  O       A        -32.178    7.656   0.640  1.00 54.77           O\nATOM     60  CB      A        -35.079    6.191   1.993  1.00 58.20           C\nATOM     61  CG      A        -35.615    7.603   2.156  1.00 55.61           C\nATOM     62  OD1     A        -36.782    7.745   2.593  1.00 55.40           O\nATOM     63  OD2     A        -34.876    8.561   1.843  1.00 55.57           O\nATOM     64  N       A        -33.583    6.349  -0.515  1.00 54.36           N\nATOM     65  CA      A        -33.167    6.876  -1.814  1.00 53.16           C\nATOM     66  C       A        -33.626    8.317  -2.061  1.00 51.53           C\nATOM     67  O       A        -33.041    9.039  -2.874  1.00 50.28           O\nATOM     68  CB      A        -33.673    5.962  -2.929  1.00 56.36           C\nATOM     69  CG      A        -33.144    4.523  -2.821  1.00 59.12           C\nATOM     70  CD      A        -33.329    3.750  -4.125  1.00 57.06           C\nATOM     71  CE      A        -32.718    2.350  -4.022  1.00 60.09           C\nATOM     72  NZ      A        -32.740    1.596  -5.327  1.00 61.46           N\nATOM     73  N       A        -34.685    8.721  -1.368  1.00 48.02           N\nATOM     74  CA      A        -35.197   10.077  -1.478  1.00 42.97           C\nATOM     75  C       A        -34.131   10.992  -0.891  1.00 43.60           C\nATOM     76  O       A        -33.858   12.059  -1.426  1.00 44.56           O\nATOM     77  CB      A        -36.487   10.260  -0.668  1.00 40.66           C\nATOM     78  CG1     A        -37.593    9.371  -1.249  1.00 39.01           C\nATOM     79  CG2     A        -36.885   11.737  -0.658  1.00 39.33           C\nATOM     80  CD1     A        -38.855    9.309  -0.390  1.00 36.41           C\nIn the second part of the practical, you are given a PDB file (see above) for a polypeptide that is missing its amino acid labels. You will need to open the file using PyMOL, identify the polypeptide’s N and C terminals, and fill in the three-letter code for each ATOM record’s amino acid in columns 18 to 20."
  },
  {
    "objectID": "P3.html",
    "href": "P3.html",
    "title": "12  Linux Command Line",
    "section": "",
    "text": "Week 3’s practical aims to provide an introduction to the Linux command line. Ths Linux command line is crucial to know for"
  }
]